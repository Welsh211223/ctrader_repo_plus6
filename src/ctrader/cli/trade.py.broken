from __future__ import annotations

"""
ctrader.cli.trade
- Rebalancing CLI with safety rails:
  * run lock (no overlaps)
  * risk-off cash buffer (BTC < SMA200)
  * drift threshold
  * turnover cap (gross/net) with adaptive mode and order priority
  * cooldown per-asset (bypass on big drift)
  * circuit breakers (missing prices / max trades / max notional)
  * CoinSpot buy-price & CoinGecko fallbacks (planning only)
  * guard preview (no live orders)
  * signals/plan/summary logs + JSONL run log
  * Discord/Slack optional notifications
"""
# --- path shim so 'import ctrader' works if run by absolute script path ---
import sys
from pathlib import Path

SRC_DIR = Path(__file__).resolve().parents[3]  # ...\src
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))
# --------------------------------------------------------------------------

import argparse
import csv
import json
import os
from datetime import datetime, timedelta, timezone

import pandas as pd
from dotenv import load_dotenv

from ctrader.analytics import append_trades, update_equity_and_pnl
from ctrader.config_loader import load_pools_config
from ctrader.data_providers.coinspot import (fetch_buy_price,
                                             fetch_prices_coinspot)
from ctrader.data_providers.marketdata import fetch_history_daily
from ctrader.execution.coinspot_execution import place_plan_coinspot
from ctrader.execution.paper import PaperLedger, simulate_exec
from ctrader.notify import post_discord_embed
from ctrader.portfolio import (compute_drift, compute_targets, load_holdings,
                               save_holdings)
from ctrader.risk.rebalancer import (any_drift_exceeds_threshold,
                                     create_rebalance_plan)
from ctrader.risk.risk_manager import RiskRules, enforce_caps
from ctrader.strategies.inverse_vol import inverse_vol_weights
from ctrader.strategies.momentum import boost_top_k, momentum_12_1
from ctrader.strategies.trend_filter import apply_trend_filter

# --------------------------- helpers ---------------------------

def _sma(series, window: int) -> float:
    if not series or window <= 0 or len(series) < window:
        return float("nan")
    return sum(series[-window:]) / float(window)


def _risk_off_trigger(cfg: dict, quote: str) -> bool:
    """
    Absolute momentum risk-off: if ref asset (default BTC) is below its SMA-200 (USD history),
    we return True to apply extra reserve.
    """
    ro = cfg.get("risk_off", {}).get("absolute_momentum", {})
    if not ro or not bool(ro.get("enabled", False)):
        return False
    sym = str(ro.get("ref_symbol", "BTC")).upper()
    days = int(ro.get("sma_days", 200))
    hist = fetch_history_daily(sym, vs="usd", days=max(365, days + 30))
    px = [p for _, p in hist]
    if len(px) < days:
        return False
    sma = _sma(px, days)
    return px[-1] < sma


def _read_eq_stats(pool: str) -> dict:
    """
    Lightweight equity stats from data/equity_{pool}.csv:
      - max_drawdown (negative number)
      - vol_daily (std dev of daily pct change)
    Safe if file missing/empty.
    """
    eq_fp = Path(__file__).resolve().parents[3] / "data" / f"equity_{pool}.csv"
    if not eq_fp.exists():
        return {"max_drawdown": 0.0, "vol_daily": 0.0}
    try:
        df = pd.read_csv(eq_fp)
        if "equity" not in df or len(df) < 3:
            return {"max_drawdown": 0.0, "vol_daily": 0.0}
        eq = pd.to_numeric(df["equity"], errors="coerce").dropna()
        if eq.empty:
            return {"max_drawdown": 0.0, "vol_daily": 0.0}
        r = eq.pct_change().dropna()
        vol_daily = float(r.std()) if not r.empty else 0.0
        cummax = eq.cummax()
        dd = eq / cummax - 1.0
        max_dd = float(dd.min()) if not dd.empty else 0.0
        return {"max_drawdown": max_dd, "vol_daily": vol_daily}
    except Exception:
        return {"max_drawdown": 0.0, "vol_daily": 0.0}


def _adaptive_cap_pct(base_pct: float, pool: str, risk_off: bool) -> tuple[float, list[str]]:
    """
    Adaptive rules:
      - if risk_off -> cap = min(base, 10%)   (reason: risk_off)
      - if vol > 3% OR max_drawdown < -10% -> reduce by 40% (floor 5%) (reasons: high_vol, deep_dd)
      - if vol < 1% AND max_drawdown > -3% -> increase by 25% (cap 60%) (reason: calm)
    Returns (cap_pct, reasons[])
    """
    pct = float(base_pct)
    reasons: list[str] = []
    stats = _read_eq_stats(pool)
    vol = float(stats.get("vol_daily", 0.0))
    mdd = float(stats.get("max_drawdown", 0.0))  # negative in drawdown

    if risk_off:
        reasons.append("risk_off")
        pct = min(pct, 10.0)
    else:
        high_vol = vol > 0.03     # >3% daily vol
        deep_dd = mdd < -0.10     # deeper than -10%
        calm = (vol < 0.01) and (mdd > -0.03)

        if high_vol or deep_dd:
            if high_vol: reasons.append("high_vol")
            if deep_dd: reasons.append("deep_dd")
            pct = max(5.0, pct * 0.60)
        elif calm:
            reasons.append("calm")
            pct = min(60.0, pct * 1.25)

    return float(pct), reasons


class RunLock:
    """
    Simple file lock to prevent overlapping runs.
    """
    def __init__(self, lock_path: Path):
        self.lock_path = lock_path

    def acquire(self) -> bool:
        try:
            self.lock_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.lock_path, "x", encoding="utf-8") as f:
                f.write(f"pid={os.getpid()} ts={datetime.now(timezone.utc).isoformat()}\n")
            return True
        except FileExistsError:
            return False

    def release(self) -> None:
        try:
            if self.lock_path.exists():
                self.lock_path.unlink()
        except Exception:
            pass


def _load_last_trade_times(pool: str) -> dict[str, datetime]:
    """
    Read the trade log and return last trade timestamp per ticker.
    """
    base = Path(__file__).resolve().parents[3] / "data"
    fp = base / f"trades_{pool}.csv"
    out: dict[str, datetime] = {}
    if not fp.exists():
        return out
    try:
        df = pd.read_csv(fp)
        if "ts" not in df or "ticker" not in df:
            return out
        for _, row in df[["ticker", "ts"]].dropna().iterrows():
            try:
                dt = datetime.fromisoformat(str(row["ts"]).replace("Z", "+00:00"))
            except Exception:
                continue
            tck = str(row["ticker"]).upper()
            old = out.get(tck)
            out[tck] = dt if (old is None or dt > old) else old
    except Exception:
        pass
    return out


def _coingecko_ids() -> dict[str, str]:
    # minimal map; extend as needed
    return {
        "BTC": "bitcoin",
        "ETH": "ethereum",
        "SOL": "solana",
        "XRP": "ripple",
        "DOGE": "dogecoin",
        "SHIB": "shiba-inu",
        "HBAR": "hedera-hashgraph",
        "QNT": "quant-network",
        "AVAX": "avalanche-2",
    }


def _coingecko_simple_price(symbols: list[str], vs: str) -> dict[str, float]:
    """
    Lightweight spot fallback via CoinGecko simple price.
    Returns mapping TICKER -> price_in_vs (float), skips unknowns.
    Planning-only safety: never used to place live orders.
    """
    import requests  # local import so requests isn't strictly required if fallback isn't used
    ids_map = _coingecko_ids()
    ids = [ids_map[s] for s in symbols if s in ids_map]
    if not ids:
        return {}
    url = "https://api.coingecko.com/api/v3/simple/price"
    try:
        r = requests.get(url, params={"ids": ",".join(ids), "vs_currencies": vs.lower()}, timeout=6)
        r.raise_for_status()
        data = r.json() or {}
        out: dict[str, float] = {}
        for sym in symbols:
            cid = ids_map.get(sym)
            if not cid:
                continue
            v = data.get(cid, {}).get(vs.lower())
            if v is not None:
                out[sym] = float(v)
        return out
    except Exception:
        return {}


def _validate_pool_config(cfg: dict, pool: str) -> list[str]:
    """
    Basic sanity checks: returns list of warnings/errors (strings). Non-empty means something to fix.
    """
    issues: list[str] = []
    try:
        pcfg = cfg["pools"][pool]
        assets = pcfg.get("assets", {})
        if not isinstance(assets, dict) or not assets:
            issues.append("assets missing/empty")
        else:
            for k, v in assets.items():
                if not isinstance(v, (int, float)) or v < 0:
                    issues.append(f"asset weight invalid: {k} -> {v}")
        cat = pcfg.get("categories", {})
        akeys = set(assets.keys())
        ckeys = set()
        for _, toks in (cat or {}).items():
            ckeys.update([str(t).upper() for t in (toks or [])])
        unknown = ckeys - set([k.upper() for k in akeys])
        if unknown:
            issues.append(f"categories reference unknown assets: {sorted(list(unknown))}")
    except Exception as e:
        issues.append(f"config parse error: {e}")
    return issues


# --------------------------- main ---------------------------

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", default=str(Path(__file__).resolve().parents[3] / "config" / "pools.yaml"))
    ap.add_argument("--pool", choices=["conservative", "aggressive"], required=True)

    # modes & safety
    ap.add_argument("--paper", action="store_true")
    ap.add_argument("--mode", choices=["both", "buy", "sell"], default="both")
    ap.add_argument("--max-trades", type=int, default=None)
    ap.add_argument("--preview-guards", action="store_true")
    ap.add_argument("--notify", action="store_true")

    # coinspot guard / thresholds
    ap.add_argument("--coinspot-use-quote", action="store_true")
    ap.add_argument("--coinspot-threshold", type=float, default=None)
    ap.add_argument("--coinspot-direction", type=str, default=None, choices=["UP", "DOWN", "BOTH"])
    ap.add_argument("--guard", type=float, default=None)  # alias for threshold

    # sizing & constraints
    ap.add_argument("--min-cash-reserve-pct", type=float, default=0.0)
    ap.add_argument("--min-order-value", type=float, default=5.0)
    ap.add_argument("--qty-precision", type=str, default="BTC:6,ETH:6,SOL:6,AVAX:6,HBAR:6,QNT:6,DOGE:0,SHIB:0,XRP:2")

    # turnover cap controls
    ap.add_argument("--turnover-cap-pct", type=float, default=None, help="Override execution.turnover_cap_pct for this run (percent of equity).")
    ap.add_argument("--turnover-cap-mode", choices=["gross", "net"], default="gross", help="gross = sum notionals; net = buys - sells (more permissive).")
    ap.add_argument("--turnover-priority", choices=["sell_first", "largest_first", "drift_first"], default="sell_first", help="Which trades to include first under the cap.")
    ap.add_argument("--turnover-adaptive", action="store_true", help="Adapt cap using vol/drawdown & risk-off; notifies Discord with reasons when --notify.")

    # circuit breakers & cooldown
    ap.add_argument("--max-trades-hard", type=int, default=50, help="Abort if plan has more than this many trades after capping.")
    ap.add_argument("--max-notional-pct-hard", type=float, default=80.0, help="Abort if gross notional exceeds this % of equity (post cap).")
    ap.add_argument("--missing-price-pct-hard", type=float, default=50.0, help="Abort if more than this % of assets have missing/zero prices.")
    ap.add_argument("--cooldown-minutes", type=int, default=0, help="Skip re-trading same ticker within this many minutes unless bypassed by drift.")
    ap.add_argument("--cooldown-bypass-drift-pct", type=float, default=3.0, help="If absolute position drift exceeds this %, bypass cooldown for that ticker.")

    # price fallback
    ap.add_argument("--fallback-coingecko", action="store_true", help="Use CoinGecko simple price as final fallback for missing/zero prices (planning only).")

    # polling (live)
    ap.add_argument("--order-timeout-sec", type=int, default=30)
    ap.add_argument("--poll-interval-sec", type=int, default=2)

    # run-time quality-of-life
    ap.add_argument("--offline", action="store_true")
    ap.add_argument("--cache-ttl", type=int, default=None)

    args = ap.parse_args()

    # env
    load_dotenv()
    if args.offline:
        os.environ["OFFLINE_MODE"] = "true"
    if args.cache_ttl is not None:
        os.environ["CACHE_TTL_SEC"] = str(args.cache_ttl)

    # run-lock (prevents overlapping runs)
    lock_file = Path(__file__).resolve().parents[3] / "data" / "locks" / f".run_{args.pool}.lock"
    run_lock = RunLock(lock_file)
    if not run_lock.acquire():
        print(f"Another run appears to be in progress (lock: {lock_file}). Exiting.")
        return

    # Optional Slack webhook (if present)
    SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK", "").strip()

    def _slack(text: str, fields: dict | None = None):
        if not args.notify:
            return
        if not SLACK_WEBHOOK:
            return
        try:
            import requests
            blocks = [{"type": "section", "text": {"type": "mrkdwn", "text": text}}]
            if fields:
                items = "\n".join([f"*{k}*: `{v}`" for k, v in fields.items()])
                blocks.append({"type": "section", "text": {"type": "mrkdwn", "text": items}})
            requests.post(SLACK_WEBHOOK, json={"blocks": blocks}, timeout=5)
        except Exception:
            pass

    try:
        # config
        cfg = load_pools_config(args.config)
        issues = _validate_pool_config(cfg, args.pool)
        if issues:
            msg = "Config issues: " + "; ".join(issues)
            print(msg)
            if args.notify:
                # prefer .env webhook if YAML is blank
                gtmp = cfg.get("global", {})
                webhook_tmp = (gtmp.get("webhook_url", "") or os.getenv("DISCORD_WEBHOOK", "")).strip()
                if webhook_tmp:
                    post_discord_embed(webhook_tmp, "Config issues", msg)
                _slack("Config issues", {"issues": msg})

        g = cfg.get("global", {})
        pcfg = cfg["pools"][args.pool]
        quote = g.get("quote_currency", "AUD").upper()
        fee_bps = float(g.get("fee_bps", 10))
        slip_bps = float(g.get("slippage_bps", 5))
webhook = (g.get("webhook_url", "") or os.getenv("DISCORD_WEBHOOK", "")).strip()

        # --- config-driven execution defaults with CLI override ---
        exec_cfg = cfg.get("execution", {})
        cfg_min_order_value = float(exec_cfg.get("min_order_value_default", args.min_order_value))
        if args.min_order_value == 5.0 and "min_order_value_default" in exec_cfg:
            args.min_order_value = cfg_min_order_value

        cfg_qprec = exec_cfg.get("qty_precision", {}) or {}
        if cfg_qprec and (args.qty_precision == "BTC:6,ETH:6,SOL:6,AVAX:6,HBAR:6,QNT:6,DOGE:0,SHIB:0,XRP:2"):
            args.qty_precision = ",".join([f"{k}:{v}" for k, v in cfg_qprec.items()])
        # -----------------------------------------------------------

        # quantity precision map
        qmap: dict[str, int] = {}
        for part in (args.qty_precision or "").split(","):
            if not part.strip():
                continue
            sym, _, dec = part.partition(":")
            try:
                qmap[sym.strip().upper()] = int(dec)
            except Exception:
                pass

        # === BASE WEIGHTS + ADJUSTMENTS ===
        w = dict(pcfg["assets"])
        w = apply_trend_filter(w, os.getenv("EXCHANGE_ID", "binance"), quote, int(g.get("trend_filter_sma_days", 200)), float(g.get("trend_min_weight", 0.25)))
        if cfg.get("sizing", {}).get("risk_parity", True):
            szz = cfg["sizing"]
            w = inverse_vol_weights(w, os.getenv("EXCHANGE_ID", "binance"), quote, int(szz.get("vol_lookback_days", 30)), float(szz.get("vol_floor", 0.0005)), float(szz.get("risk_parity_strength", 1.0)))
        if cfg.get("momentum", {}).get("enabled", True):
            mom = cfg["momentum"]
            scores = momentum_12_1(list(w.keys()), os.getenv("EXCHANGE_ID", "binance"), quote, int(mom.get("lookback_months", 12)), int(mom.get("skip_recent_months", 1)))
            w = boost_top_k(w, scores, int(mom.get("top_k", 6)), float(mom.get("momentum_boost_pct", 0.04)))

        # === RISK CAPS ===
        rules = RiskRules(float(pcfg.get("max_per_asset_pct", 100)), float(pcfg.get("max_meme_bucket_pct", 100)), float(pcfg.get("max_ai_bucket_pct", 100)), pcfg.get("per_asset_caps", {}))
        w = enforce_caps(w, pcfg.get("categories", {}), rules)

        # === PRICES ===
        symbols = list(w.keys())
        prices = fetch_prices_coinspot(symbols, market=quote)

        # Fallback for any missing/zero prices from /pubapi/v2/latest -> buyprice
        missing_syms = []
        for t in symbols:
            try:
                if float(prices.get(t, 0.0)) <= 0.0:
                    missing_syms.append(t)
                    bp = fetch_buy_price(t, quote)
                    if bp:
                        prices[t] = float(bp)
            except Exception:
                missing_syms.append(t)

        # Optional: CoinGecko fallback for stubborn missers (planning only)
        if args.fallback_coingecko and missing_syms:
            gecko = _coingecko_simple_price(missing_syms, quote)
            for t, v in gecko.items():
                if float(prices.get(t, 0.0)) <= 0.0 and v > 0.0:
                    prices[t] = float(v)

        # Missing-price circuit breaker
        miss_after = sum(1 for t in symbols if float(prices.get(t, 0.0)) <= 0.0)
        miss_pct = 100.0 * miss_after / max(1, len(symbols))
        threshold = float(getattr(args, "missing_price_pct_hard", 50.0))
        if miss_pct > threshold:
            msg = f"Hard break: {miss_pct:.1f}% of assets missing price (threshold {threshold:.1f}%). Aborting."
            print(msg)
            if args.notify and webhook:
                post_discord_embed(webhook, "Circuit breaker: missing prices", msg)
            _slack("Circuit breaker: missing prices", {"missing_pct": f"{miss_pct:.1f}%"})
            return

        # === HOLDINGS + TARGETS ===
        hbase = Path(__file__).resolve().parents[3] / "data" / "portfolios"
        current = load_holdings(args.pool, hbase)
        equity = float(pcfg.get("initial_equity", 10000))

        # risk-off cash buffer
        risk_off = _risk_off_trigger(cfg, quote)
        extra = float(cfg.get("risk_off", {}).get("absolute_momentum", {}).get("extra_reserve_pct", 0.0)) if risk_off else 0.0
        total_reserve_pct = (args.min_cash_reserve_pct or 0.0) + extra
        reserve = equity * (total_reserve_pct / 100.0) if args.paper else 0.0

        # Notify risk state (Discord/Slack)
        if args.notify and webhook:
            post_discord_embed(webhook, "Risk state", f"Pool: {args.pool}", fields={
                "risk_off": str(risk_off),
                "extra_reserve_pct": f"{extra:.1f}%",
                "baseline_reserve_pct": f"{(args.min_cash_reserve_pct or 0.0):.1f}%",
                "total_reserve_pct": f"{total_reserve_pct:.1f}%",
            })
        _slack("Risk state", {"risk_off": str(risk_off), "extra_reserve_pct": f"{extra:.1f}%", "baseline_reserve_pct": f"{(args.min_cash_reserve_pct or 0.0):.1f}%", "total_reserve_pct": f"{total_reserve_pct:.1f}%"})

        targets = compute_targets(equity - reserve, w, prices)

        # === REPORTS ===
        drift = compute_drift(current, prices, targets)
        print("\n=== DRIFT REPORT ===")
        print(drift.to_string(index=False))

        # Drift alert to Discord if threshold breached
        thresh_cfg = float(cfg.get("rebalance", {}).get("threshold_pct", 0.0))
        if args.notify and webhook and thresh_cfg > 0:
            drift_breach = any_drift_exceeds_threshold(current, targets, thresh_cfg)
            if drift_breach:
                post_discord_embed(webhook, "Drift threshold breached", f"Pool: {args.pool}, threshold: {thresh_cfg}%")

        plan = create_rebalance_plan(current, targets, prices, float(cfg.get("rebalance", {}).get("threshold_pct", 0.0)), min_order_value=float(args.min_order_value), qty_precision=qmap)

        # Per-asset cooldown filter
        if args.cooldown_minutes > 0:
            last_ts = _load_last_trade_times(args.pool)
            cutoff = datetime.now(timezone.utc) - timedelta(minutes=int(args.cooldown_minutes))
            kept_rows = []
            for _, r in plan.iterrows():
                t = str(r["ticker"]).upper()
                side = str(r["side"]).upper()
                if side == "HOLD":
                    kept_rows.append(r); continue
                lt = last_ts.get(t)
                if lt and lt > cutoff:
                    # bypass if big drift relative to equity
                    try:
                        row = drift.loc[drift["ticker"] == t].iloc[0]
                        if abs(float(row.get("est_value", 0.0))) / max(1.0, equity) * 100.0 >= float(args.cooldown_bypass_drift_pct):
                            kept_rows.append(r); continue
                    except Exception:
                        pass
                    # else skip due to cooldown
                    continue
                kept_rows.append(r)
            plan = pd.DataFrame(kept_rows) if kept_rows else plan.iloc[0:0]

        print("\n=== PLAN ===")
        print(plan.to_string(index=False))

        # ---------------- Turnover Cap (smart & optional) ----------------
        exec_cfg = cfg.get("execution", {})
        base_cap_pct = float(exec_cfg.get("turnover_cap_pct", 20.0))
        if args.turnover_cap_pct is not None:
            base_cap_pct = float(args.turnover_cap_pct)

        cap_applied_pct = 0.0
        cap_reasons: list[str] = []
        cap_mode = args.turnover_cap_mode
        cap_priority = args.turnover_priority

        if base_cap_pct > 0.0:
            cap_pct = base_cap_pct
            reasons: list[str] = []

            if args.turnover_adaptive:
                cap_pct, reasons = _adaptive_cap_pct(base_cap_pct, args.pool, risk_off)

            cap_applied_pct = cap_pct
            cap_reasons = reasons
            cap_value = (equity * cap_pct) / 100.0

            # Notify about cap before applying
            if args.notify and webhook:
                fields = {
                    "base_cap_pct": f"{base_cap_pct:.1f}%",
                    "adaptive_cap_pct": f"{cap_pct:.1f}%" if args.turnover_adaptive else "n/a",
                    "mode": cap_mode,
                    "priority": cap_priority,
                    "cap_value": f"{cap_value:.2f}",
                    "reasons": ", ".join(reasons) if reasons else "none",
                    "risk_off": str(risk_off),
                    "extra_reserve_pct": f"{extra:.1f}%",
                }
                post_discord_embed(webhook, "Turnover cap applied", f"Pool: {args.pool}", fields=fields)

            rows = plan.to_dict("records")
            # Priority ordering
            if cap_priority == "sell_first":
                rows_sorted = sorted(rows, key=lambda r: (0 if r["side"] == "SELL" else 1, -float(r["est_value"])))
            elif cap_priority == "largest_first":
                rows_sorted = sorted(rows, key=lambda r: -float(r["est_value"]))
            else:  # drift_first ~= largest_notional
                rows_sorted = sorted(rows, key=lambda r: -float(r["est_value"]))

            kept = []
            gross_spent = 0.0

            if cap_mode == "net":
                net_spent = 0.0
                for r in rows_sorted:
                    v = float(r["est_value"])
                    if v <= 0.0 or r["side"] == "HOLD":
                        continue
                    delta = (-v) if r["side"] == "SELL" else v
                    new_net = net_spent + delta
                    new_gross = gross_spent + v
                    # Keep gross within 2x cap as a sanity brake; allow net within cap
                    if (abs(new_net) <= cap_value) and (new_gross <= 2.0 * cap_value):
                        kept.append(r)
                        net_spent = new_net
                        gross_spent = new_gross
            else:  # gross mode
                for r in rows_sorted:
                    v = float(r["est_value"])
                    if v <= 0.0 or r["side"] == "HOLD":
                        continue
                    if (gross_spent + v) <= cap_value:
                        kept.append(r)
                        gross_spent += v

            plan = pd.DataFrame(kept) if kept else plan.iloc[0:0]
            print(f"Applied turnover cap {cap_pct:.1f}% ({'net' if cap_mode=='net' else 'gross'}) -> notional cap {cap_value:.2f}, selected {len(plan)} trades")
        # ------------------------------------------------------------------

        # Circuit breakers (post-cap)
        gross_notional = float(plan["est_value"].sum()) if len(plan) else 0.0
        if args.max_trades_hard is not None and len(plan) > int(args.max_trades_hard):
            msg = f"Hard break: trades={len(plan)} > max_trades_hard={args.max_trades_hard}. Aborting."
            print(msg)
            if args.notify and webhook:
                post_discord_embed(webhook, "Circuit breaker tripped", msg, fields={"trades": len(plan)})
            _slack("Circuit breaker tripped", {"trades": len(plan)})
            return

        if args.max_notional_pct_hard is not None:
            if gross_notional > (equity * float(args.max_notional_pct_hard) / 100.0):
                msg = f"Hard break: gross notional {gross_notional:.2f} exceeds {args.max_notional_pct_hard:.1f}% of equity. Aborting."
                print(msg)
                if args.notify and webhook:
                    post_discord_embed(webhook, "Circuit breaker tripped", msg)
                _slack("Circuit breaker tripped", {"gross_notional": f"{gross_notional:.2f}"})
                return

        # Per-run CSV (plan snapshot)
        summaries = Path(__file__).resolve().parents[3] / "data" / "run_summaries"
        summaries.mkdir(parents=True, exist_ok=True)
        run_ts = datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')
        run_file = summaries / f"run_{args.pool}_{run_ts}_trades.csv"
        with open(run_file, "w", newline="", encoding="utf-8") as f:
            wcsv = csv.writer(f)
            wcsv.writerow(["ticker", "side", "qty", "est_value", "price_used"])
            for _, r in plan.iterrows():
                wcsv.writerow([r["ticker"], r["side"], float(r["qty"]), float(r["est_value"]), float(prices.get(r["ticker"], 0.0))])
        print(f"\nSaved run summary: {run_file}")

        # Signals log (audit)
        import csv as _csv

        from ctrader.data_providers.marketdata import \
            fetch_history_daily as _hist
        from ctrader.strategies.momentum import momentum_12_1 as _mom_12_1

        sig_dir = Path(__file__).resolve().parents[3] / "data" / "signals"
        sig_dir.mkdir(parents=True, exist_ok=True)
        sig_file = sig_dir / f"signals_{args.pool}_{run_ts}.csv"
        with open(sig_file, "w", newline="", encoding="utf-8") as sf:
            wcsv = _csv.writer(sf)
            wcsv.writerow(["ticker", "price_usd", "sma200", "mom_12_1"])
            for t in symbols:
                h = _hist(t, vs="usd", days=430)
                series = [p for _, p in h]
                px = series[-1] if series else 0.0
                sma200 = _sma(series, 200)
                scores = _mom_12_1([t], os.getenv("EXCHANGE_ID", "binance"), quote, 12, 1)
                wcsv.writerow([t, px, sma200, scores.get(t, 0.0)])
        print(f"Saved signals: {sig_file}")

        # === GUARD PREVIEW (no live orders) ===
        thresh = args.guard if args.guard is not None else args.coinspot_threshold
        if args.preview_guards and (args.coinspot_use_quote or thresh is not None):
            print("\n=== GUARD PREVIEW ===")
            for _, r in plan.iterrows():
                t = r["ticker"]; side = r["side"]; q = float(r["qty"])
                if side == "HOLD" or abs(q) < 1e-9:
                    print(f"{t}: HOLD"); continue
                ref = float(prices.get(t, 0.0)) if args.coinspot_use_quote else None
                if ref is None or thresh is None:
                    print(f"{t}: {side} qty={q:.6f} (no guard)")
                else:
                    print(f"{t}: {side} qty={q:.6f} guard -> ref={ref}, threshold={thresh}%, direction={args.coinspot_direction or 'n/a'}")
            print("No live orders executed due to --preview-guards.")
            return

        # Notify helper for per-trade embeds
        def notify_embed(ev: dict):
            if not args.notify or not webhook:
                return
            title = f"{ev.get('side', '?')} {ev.get('ticker', '?')}"
            desc = f"qty: {ev.get('qty')}, status: {ev.get('status')}, filled: {ev.get('fill_status', {}).get('filled', '?')}"
            fields = {}
            if "error" in ev:
                fields["error"] = ev["error"]
            if "error_type" in ev:
                fields["error_type"] = ev["error_type"]
            post_discord_embed(webhook, title, desc, color=3066993 if ev.get("status") in ("ok", "success") else 15158332, fields=fields)

        # === EXECUTE ===
        if args.paper or g.get("execution_broker", "none") == "none":
            # Paper simulation
            hv = sum(current.get(t, 0.0) * prices.get(t, 0.0) for t in current)
            ledger = PaperLedger(max(0.0, equity - hv), current or {s: 0.0 for s in symbols})
            ledger = simulate_exec(ledger, plan, prices, fee_bps, slip_bps)
            updated = ledger.holdings
            if args.notify and webhook:
                post_discord_embed(webhook, "Paper run complete", f"Pool: {args.pool}", fields={"trades": len(plan)})
            _slack("Paper run complete", {"trades": len(plan)})
        else:
            # Live (CoinSpot V2)
            res = place_plan_coinspot(plan, prices, quote, use_quote=args.coinspot_use_quote, threshold_pct=thresh, direction=args.coinspot_direction, mode=args.mode, max_trades=args.max_trades, notify=notify_embed if args.notify and webhook else None, order_timeout_sec=int(args.order_timeout_sec), poll_interval_sec=int(args.poll_interval_sec))
            updated = current.copy()
            for _, r in plan.iterrows():
                if r["side"] == "BUY":
                    updated[r["ticker"]] = updated.get(r["ticker"], 0.0) + float(r["qty"])
                elif r["side"] == "SELL":
                    updated[r["ticker"]] = max(0.0, updated.get(r["ticker"], 0.0) - abs(float(r["qty"])))
            print("\n=== LIVE RESULTS ===")
            for x in res:
                print(x)
            if args.notify and webhook:
                post_discord_embed(webhook, "Live run complete", f"Pool: {args.pool}", fields={"trades": len(res)})
            _slack("Live run complete", {"trades": len(plan)})

        # persist
        base_data = Path(__file__).resolve().parents[3] / "data"
        save_holdings(args.pool, updated, base_data / "portfolios")
        append_trades(args.pool, plan, base_data)
        update_equity_and_pnl(args.pool, updated, prices, base_data)
        print("\nSaved holdings and updated equity/PnL/trade logs.")

        # Run-level JSONL log (for BI/audit)
        logs_dir = base_data / "logs"
        logs_dir.mkdir(parents=True, exist_ok=True)
        runlog = {
            "ts": run_ts,
            "pool": args.pool,
            "equity": equity,
            "reserve_pct": total_reserve_pct,
            "risk_off": risk_off,
            "cap_pct": cap_applied_pct,
            "cap_mode": cap_mode,
            "cap_priority": cap_priority,
            "cap_reasons": cap_reasons,
            "gross_notional": gross_notional,
            "trades_selected": int(len(plan)),
            "missing_price_pct": miss_pct,
            "paper": bool(args.paper),
        }
        with open(logs_dir / "runs.jsonl", "a", encoding="utf-8") as jf:
            jf.write(json.dumps(runlog) + "\n")

    finally:
        # always release the run lock
        run_lock.release()


if __name__ == "__main__":
    main()


